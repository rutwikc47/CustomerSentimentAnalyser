{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data Sentiment Analysis \n",
    "\n",
    "#### Perform Sentiment Analysis using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from pathlib import Path\n",
    "from pyspark.sql import SparkSession\n",
    "from boto3.session import Session\n",
    "import seaborn as sns\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Amazon S3 Credentials (Note:- Our access and secret keys are removed for security purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY = 'MYACCESSKEY'\n",
    "SECRET_KEY = 'MYSECRETKEY'\n",
    "BUCKET_NAME = 'yelpbigdata'\n",
    "PREFIX = 'root'\n",
    "MAX_FILES_READ = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session(aws_access_key_id=ACCESS_KEY, aws_secret_access_key=SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = session.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.Bucket(name='yelpbigdata')\n"
     ]
    }
   ],
   "source": [
    "my_bucket = s3.Bucket(BUCKET_NAME)\n",
    "print(my_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('BDF').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", ACCESS_KEY)\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", SECRET_KEY)\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "spark._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.aws.credentials.provider\",\"org.apache.hadoop.fs.s3a.BasicAWSCredentialsProvider\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3-eu-west-1.amazonaws.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Data from the S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bucket.download_file('yelp_business.csv',\"business.csv\")\n",
    "my_bucket.download_file('yelp_review.csv',\"review.csv\")\n",
    "my_bucket.download_file('yelp_tip.csv',\"tip.csv\")\n",
    "my_bucket.download_file('yelp_user.csv',\"user.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review File cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = spark.read.format(\"com.databricks.spark.csv\").option(\"wholeFile\", \"true\").option(\"multiline\",\"true\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"delimiter\", \",\").option(\"encoding\", \"ISO-8859-1\").option(\"charset\", \"ISO-8859-1\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").load(\"/content/review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|As someone who ha...|\n",
      "|I am actually hor...|\n",
      "|I love Deagan's. ...|\n",
      "|Dismal, lukewarm,...|\n",
      "|Oh happy day, fin...|\n",
      "|This is definitel...|\n",
      "|Really good place...|\n",
      "|Awesome office an...|\n",
      "|Most delicious au...|\n",
      "|I have been here ...|\n",
      "|Maria is VERY goo...|\n",
      "|ORDER In (Deliver...|\n",
      "|We purchased new ...|\n",
      "|Everything that m...|\n",
      "|Called for a 5:15...|\n",
      "|If I could give l...|\n",
      "|10pm on a super b...|\n",
      "|A close friend wa...|\n",
      "|Tried to have my ...|\n",
      "|My husband and I ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Delete the quotation marks, commas, \\n from text column\n",
    "from pyspark.sql.functions import *\n",
    "df_review.select('text').show()\n",
    "df_review = df_review.withColumn('text', regexp_replace('text', ',', ''))\n",
    "df_review = df_review.withColumn('text', regexp_replace('text', '\"\"', ''))\n",
    "df_review = df_review.withColumn('text', regexp_replace('text', '\\r\\n', ''))\n",
    "df_review = df_review.withColumn('text', regexp_replace('text', '\\n', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- stars: integer (nullable = true)\n",
      " |-- useful: integer (nullable = true)\n",
      " |-- funny: integer (nullable = true)\n",
      " |-- cool: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_review=df_review.drop('_c0')\n",
    "df_review.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               date|\n",
      "+-------------------+\n",
      "|2015-04-15 05:21:16|\n",
      "|2013-12-07 03:16:52|\n",
      "|2015-12-05 03:18:11|\n",
      "|2011-05-27 05:30:52|\n",
      "|2017-01-14 21:56:57|\n",
      "|2013-05-07 07:25:25|\n",
      "|2015-11-05 23:11:05|\n",
      "|2017-07-18 18:31:54|\n",
      "|2015-02-16 06:48:47|\n",
      "|2009-10-13 04:16:41|\n",
      "|2013-12-28 21:02:55|\n",
      "|2015-10-17 01:38:13|\n",
      "|2015-07-03 21:48:51|\n",
      "|2016-06-11 22:00:11|\n",
      "|2015-05-26 10:36:47|\n",
      "|2017-08-07 21:36:36|\n",
      "|2015-02-02 06:28:00|\n",
      "|2018-02-01 19:15:00|\n",
      "|2017-06-28 00:39:18|\n",
      "|2018-03-04 01:03:53|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_review.select('date').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = df_review.drop('review_id','text','date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = spark.read.format(\"com.databricks.spark.csv\").option(\"wholeFile\", \"true\").option(\"multiline\",\"true\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"delimiter\", \",\").option(\"encoding\", \"ISO-8859-1\").option(\"charset\", \"ISO-8859-1\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").load(\"/content/business.csv\")\n",
    "df_business = df_business.withColumnRenamed('stars', 'business_stars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As there are many columns select the ones we need instead of dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = df_business.select('business_id','state','city','latitude','longitude',\"business_stars\",\"review_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+---------------+--------+----------+--------------+------------+\n",
      "|         business_id|state|           city|latitude| longitude|business_stars|review_count|\n",
      "+--------------------+-----+---------------+--------+----------+--------------+------------+\n",
      "|f9NumwFMBDn751xgF...|   NC|      Cornelius|35.46272| -80.85261|           3.5|        36.0|\n",
      "|Yzvjg0SayhoZgCljU...|   AZ|     Scottsdale| 33.5694|-111.89026|           5.0|         4.0|\n",
      "|XNoUzKckATkOD1hP6...|   QC|       Montreal|45.47998| -73.58007|           5.0|         5.0|\n",
      "|6OAZjbxqM5ol29BuH...|   NV|North Las Vegas|36.21973|-115.12773|           2.5|         3.0|\n",
      "|51M2Kk903DFYI6gnB...|   AZ|           Mesa|33.42807|-111.72665|           4.5|        26.0|\n",
      "|cKyLV5oWZJ2NudWgq...|   AZ|        Gilbert| 33.3504|-111.82714|           4.5|        38.0|\n",
      "|oiAlXZPIFm2nBCt0D...|   NV|      Las Vegas|36.06398|-115.24146|           3.5|        81.0|\n",
      "|ScYkbYNkDgCneBrD9...|   AZ|           Mesa|33.39388|-111.68223|           5.0|        18.0|\n",
      "|pQeaRpvuhoEqudo3u...|   IL|      Champaign|40.11045| -88.23307|           4.5|         5.0|\n",
      "|EosRKXIGeSWFYWwpk...|   ON|        Toronto|43.62454| -79.52911|           3.0|        16.0|\n",
      "|MbZMmwo-eL0Jnm_Yb...|   AB|        Calgary|50.94596|-114.03721|           5.0|         3.0|\n",
      "|7Dv4_HAxsxvadEsT5...|   PA|     Pittsburgh|40.40667| -80.00445|           5.0|         5.0|\n",
      "|M_guz7Dj7hX0evS67...|   WI|      Middleton|43.10531| -89.51014|           3.5|         6.0|\n",
      "|JjJs3o60uQCfctDjs...|   AZ|       Chandler|33.30387|-111.95166|           2.5|        10.0|\n",
      "|kOICO53wbOiOJcKuC...|   NV|North Las Vegas|36.26336|-115.17984|           3.5|         5.0|\n",
      "|rqcOZePlVvJP9Etzl...|   NV|      Henderson|35.95205|-115.09348|           5.0|         5.0|\n",
      "|uZuh51lXu7tsrC8RA...|   NV|      Las Vegas|36.12573|-115.16761|           4.5|        32.0|\n",
      "|nIEhsGbw0vJuYl05b...|   AZ|          Tempe|33.41151|-111.89538|           4.5|         7.0|\n",
      "|edQoeeBFUTYGwnUSE...|   SC|      Rock Hill|34.98112| -80.97902|           4.5|        10.0|\n",
      "|Vwo64kNYDjKi98gUU...|   AZ|           Mesa|33.32072|-111.68587|           4.5|        16.0|\n",
      "+--------------------+-----+---------------+--------+----------+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_business.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tip-Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tip = spark.read.format(\"com.databricks.spark.csv\").option(\"wholeFile\", \"true\").option(\"multiline\",\"true\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"delimiter\", \",\").option(\"encoding\", \"ISO-8859-1\").option(\"charset\", \"ISO-8859-1\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").load(\"/content/tip.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only take necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tip = df_tip.select('user_id','business_id','compliment_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = spark.read.format(\"com.databricks.spark.csv\").option(\"wholeFile\", \"true\").option(\"multiline\",\"true\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"delimiter\", \",\").option(\"encoding\", \"ISO-8859-1\").option(\"charset\", \"ISO-8859-1\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").load(\"/content/user.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Again preprocess and take the columns we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = df_user.select('user_id','average_stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|             user_id|average_stars|\n",
      "+--------------------+-------------+\n",
      "|ntlvfPzc8eglqvk92...|         3.57|\n",
      "|FOBRPlBHa3WPHFB5q...|         3.84|\n",
      "|zZUnPeh2hEp0WydbA...|         3.44|\n",
      "|QaELAmRcDc5TfJEyl...|         3.08|\n",
      "|xvu8G900tezTzbbfq...|         4.37|\n",
      "|z5_82komKV3mI4ASG...|         2.88|\n",
      "|ttumcu6hWshk_EJVW...|          4.0|\n",
      "|f4_MRNHvN-yRn7EA8...|         3.63|\n",
      "|UYACF30806j2mfbB5...|         3.75|\n",
      "|QG13XBbgHWydzThRB...|          4.1|\n",
      "|f6YuZP6iennHFVlnF...|          3.8|\n",
      "|I_6wY8_RsewziNnKh...|         3.63|\n",
      "|q-v8elVPvKz0KvK69...|         3.37|\n",
      "|HwPGLzF_uXB3MF8bc...|          4.5|\n",
      "|y4UuVowA9i3zj2hHy...|         4.17|\n",
      "|1WBxJ2r3A2QYfRSEz...|         3.82|\n",
      "|-TT5e-YQU9xLb1JAG...|         3.91|\n",
      "|6bbHSJ0PrgSxh7e5n...|         2.21|\n",
      "|4VmuXuSRhv5UxYUy3...|         3.88|\n",
      "|pVU2DdtBFppBAX5G5...|         3.79|\n",
      "+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_table_1 = df_review.join(df_business, on='business_id', how='left_outer')\n",
    "temp_table_2 = temp_table_1.join(df_user, on='user_id', how='left_outer')\n",
    "fin_table = temp_table_2.join(df_tip, on=['business_id', 'user_id',], how='left_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- stars: integer (nullable = true)\n",
      " |-- useful: integer (nullable = true)\n",
      " |-- funny: integer (nullable = true)\n",
      " |-- cool: integer (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- business_stars: double (nullable = true)\n",
      " |-- review_count: double (nullable = true)\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- compliment_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fin_table.count()\n",
    "fin_table.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Logistic Regression\n",
    "\n",
    "#### Do the same basic steps as in svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_table = fin_table.filter(fin_table.stars.isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now convert the reviews having star rating > 3 to 1 i.e positive and 0 otherwise i.e negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df = fin_table.withColumn('stars',when(fin_table.stars <= 3, '0').otherwise('1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|stars| count|\n",
      "+-----+------+\n",
      "|    0|343758|\n",
      "|    1|674889|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fin_df.groupby(fin_df.stars).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see the number of reviews with 1 label are almost twice as compared to 0 i.e (1,2,3) combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '0']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_indexer = StringIndexer(inputCol=\"stars\", outputCol=\"label\",handleInvalid='keep').fit(fin_df)\n",
    "l_indexer.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_AssF = VectorAssembler(inputCols=[\"si_state\", \"si_city\", \"si_compliment_count\", \"useful\", \"funny\", \"cool\", \"latitude\", \"longitude\", \"business_stars\", \"review_count\", \"average_stars\"], outputCol=\"features\", handleInvalid='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_indexer = StringIndexer(inputCol=\"stars\", outputCol=\"label\",handleInvalid='keep')\n",
    "ct_indexer = StringIndexer(inputCol=\"city\", outputCol=\"si_city\",handleInvalid='keep')\n",
    "st_indexer = StringIndexer(inputCol=\"state\", outputCol=\"si_state\",handleInvalid='keep')\n",
    "cct_indexer = StringIndexer(inputCol=\"compliment_count\", outputCol=\"si_compliment_count\",handleInvalid='keep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_R = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_label = IndexToString(inputCol=\"prediction\", outputCol=\"predicted_Label\", labels=lab_indexer.fit(fin_df).labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Feature_Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_RPipe = Pipeline(stages=[lab_indexer, st_indexer, ct_indexer, cct_indexer, vect_AssF, log_R, og_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for training split it 80/20 Train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = fin_df.randomSplit([0.8, 0.2])\n",
    "test_df = data_split[1]\n",
    "train_df = data_split[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR Model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_RModel = log_RPipe.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred = log_RModel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+------+-----+----+-----+----------+--------+----------+--------------+------------+-------------+----------------+-----+--------+-------+-------------------+--------------------+--------------------+--------------------+----------+---------------+\n",
      "|         business_id|             user_id|stars|useful|funny|cool|state|      city|latitude| longitude|business_stars|review_count|average_stars|compliment_count|label|si_state|si_city|si_compliment_count|            features|       rawPrediction|         probability|prediction|predicted_Label|\n",
      "+--------------------+--------------------+-----+------+-----+----+-----+----------+--------+----------+--------------+------------+-------------+----------------+-----+--------+-------+-------------------+--------------------+--------------------+--------------------+----------+---------------+\n",
      "|-2ToCaDFpTNmmg3QF...|jDUEWiD94qQxXIUcL...|    0|     6|    3|   0|   NV| Las Vegas|36.15466|-115.15922|           1.5|       451.0|         4.27|            null|  1.0|     0.0|    0.0|                6.0|[0.0,0.0,6.0,6.0,...|[4.75052012264288...|[0.04091892063336...|       1.0|              0|\n",
      "|-FNquqGseSCVMWo7K...|XWL81LGNRqo_b5Yek...|    0|     0|    0|   0|   NV| Las Vegas|36.10708|-115.13691|           3.5|       144.0|         2.57|            null|  1.0|     0.0|    0.0|                6.0|(11,[2,6,7,8,9,10...|[5.92390818750540...|[0.28126485602986...|       1.0|              0|\n",
      "|-MC7EFxTsyKMKB3ze...|G3iHY3juwha8D99n7...|    1|     1|    1|   1|   OH|      Stow|41.16742| -81.40418|           4.0|        89.0|         2.92|            null|  0.0|     4.0|   76.0|                6.0|[4.0,76.0,6.0,1.0...|[6.66686157921902...|[0.54140330114713...|       0.0|              1|\n",
      "|-MhfebM0QIsKt87iD...|7Oe6ikklTjVBbEFw9...|    1|    13|    4|   9|   NV| Las Vegas| 36.1129|-115.17764|           3.5|       180.0|         4.35|            null|  0.0|     0.0|    0.0|                6.0|[0.0,0.0,6.0,13.0...|[7.98026438695533...|[0.90517107763387...|       0.0|              1|\n",
      "|-PGsEXB6DFTVKa1eD...|3LzCPhvkHUF_JEUyN...|    0|     0|    0|   0|   NV| Las Vegas|36.14271|-115.27834|           3.5|       325.0|         4.41|            null|  1.0|     0.0|    0.0|                6.0|(11,[2,6,7,8,9,10...|[7.63507919678722...|[0.85037010777184...|       0.0|              1|\n",
      "|-QbASY4_Am_zda7TO...|4WQ-5DaVAqId93Ftc...|    0|     1|    0|   0|   AZ|Scottsdale|33.57642|-111.88807|           2.5|        74.0|         3.87|            null|  1.0|     1.0|    3.0|                6.0|[1.0,3.0,6.0,1.0,...|[5.94284212534885...|[0.37926944100537...|       1.0|              0|\n",
      "|-SpT8Tyz2R45zSw1A...|9JSCHAgXnzQnna1a3...|    0|     1|    0|   0|   NV| Las Vegas|36.11575|-115.13896|           3.0|       143.0|         3.37|            null|  1.0|     0.0|    0.0|                6.0|[0.0,0.0,6.0,1.0,...|[6.14629416254272...|[0.35609876213470...|       1.0|              0|\n",
      "|-XH3-e3jDVdjHJq7G...|qEK_1yK05r5YB0EXv...|    0|     1|    0|   1|   IL| Champaign|40.10928| -88.23139|           3.5|        34.0|         4.07|            null|  1.0|     9.0|   22.0|                6.0|[9.0,22.0,6.0,1.0...|[7.50900838276053...|[0.81915082485996...|       0.0|              1|\n",
      "|-X_w25LQmz6SDcJIF...|YRhXAs2RiYWkQd9v3...|    1|     0|    0|   0|   NV|Enterprise|36.05534| -115.1717|           3.0|       142.0|          3.6|            null|  0.0|     0.0|  152.0|                6.0|[0.0,152.0,6.0,0....|[6.56195010717488...|[0.51302017917178...|       0.0|              1|\n",
      "|-ZGb08sDklNEJJcLq...|Oykikmdx3HZj5xxlY...|    0|     5|    0|   0|   AZ|   Phoenix|33.47495|-112.06471|           3.5|        58.0|         1.75|            null|  1.0|     1.0|    1.0|                6.0|[1.0,1.0,6.0,5.0,...|[4.41609637553871...|[0.03980151122668...|       1.0|              0|\n",
      "|-ZGb08sDklNEJJcLq...|Oykikmdx3HZj5xxlY...|    0|     8|    1|   0|   AZ|   Phoenix|33.47495|-112.06471|           3.5|        58.0|         1.75|            null|  1.0|     1.0|    1.0|                6.0|[1.0,1.0,6.0,8.0,...|[3.96324141231755...|[0.01592611537834...|       1.0|              0|\n",
      "|-a857YYdjzgOdOjFF...|_4fVJIqou00rrhU9O...|    0|     4|    1|   2|   NV| Las Vegas|36.11199|-115.17243|           4.0|       762.0|         3.76|            null|  1.0|     0.0|    0.0|                6.0|[0.0,0.0,6.0,4.0,...|[7.40458388852776...|[0.77402141168271...|       0.0|              1|\n",
      "|-a857YYdjzgOdOjFF...|_4fVJIqou00rrhU9O...|    1|     3|    0|   3|   NV| Las Vegas|36.11199|-115.17243|           4.0|       762.0|         3.76|            null|  0.0|     0.0|    0.0|                6.0|[0.0,0.0,6.0,3.0,...|[7.91651541764587...|[0.90599794723077...|       0.0|              1|\n",
      "|-dgUbX_lFqklJuf29...|NMmu4oC-YRqdi0WY9...|    0|    13|   14|  12|   AZ|   Phoenix|33.44931|-112.07194|           3.0|        59.0|         3.62|            null|  1.0|     1.0|    1.0|                6.0|[1.0,1.0,6.0,13.0...|[5.83697947663450...|[0.24362746825516...|       1.0|              0|\n",
      "|-iPc_YSSqvM1CpZxx...|VOqAAFTDe1XfdFdzr...|    0|     0|    0|   0|   AZ|  Chandler|33.32144|-111.96781|           3.5|       142.0|         3.88|            null|  1.0|     1.0|   10.0|                6.0|[1.0,10.0,6.0,0.0...|[6.88004578872385...|[0.72358940750527...|       0.0|              1|\n",
      "|-mP3F3srknwKJdJ5F...|ER6XOScVy0E8DK_2w...|    1|     0|    0|   0|   OH|  Westlake|41.46814| -81.90978|           5.0|        69.0|         3.72|               0|  0.0|     4.0|   45.0|                0.0|[4.0,45.0,0.0,0.0...|[8.09835699258103...|[0.96065865956597...|       0.0|              1|\n",
      "|-o082vExIs0VVNSuZ...|_xnrQ5Qrg1FhR86yD...|    0|     0|    0|   0|   AZ|Scottsdale|33.49526|-111.92881|           3.0|       625.0|         3.83|            null|  1.0|     1.0|    3.0|                6.0|[1.0,3.0,6.0,0.0,...|[6.41194706408478...|[0.55542298356872...|       0.0|              1|\n",
      "|-rhH9sL3XGFpoJXcx...|XjavXAYqma5QA-8e0...|    1|     0|    0|   0|   AZ|   Phoenix|33.51033|-112.02814|           4.0|       839.0|          3.7|            null|  0.0|     1.0|    1.0|                6.0|[1.0,1.0,6.0,0.0,...|[7.13398466685101...|[0.77698925478485...|       0.0|              1|\n",
      "|-s5zZEv5u9XWhx1i5...|JWPcKII-DokjJTNVB...|    1|     1|    0|   0|   AZ|Scottsdale|33.50128|-111.92309|           2.5|       276.0|         3.65|            null|  0.0|     1.0|    3.0|                6.0|[1.0,3.0,6.0,1.0,...|[5.72950748227832...|[0.30294314668358...|       1.0|              0|\n",
      "|-zbcosKSMGDhaZYN-...|WaAOt_eG0_-yLpG3f...|    1|     5|    2|   3|   NV| Las Vegas|36.11447|-115.31113|           3.5|       133.0|          3.7|            null|  0.0|     0.0|    0.0|                6.0|[0.0,0.0,6.0,5.0,...|[6.94119848604641...|[0.63699578139167...|       0.0|              1|\n",
      "+--------------------+--------------------+-----+------+-----+----+-----+----------+--------+----------+--------------+------------+-------------+----------------+-----+--------+-------+-------------------+--------------------+--------------------+--------------------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_pred.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.82632\n"
     ]
    }
   ],
   "source": [
    "bin_CE = BinaryClassificationEvaluator()\n",
    "auc_acc = bin_CE.evaluate(output_pred)\n",
    "\n",
    "print(\"Accuracy = %g\" % auc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
